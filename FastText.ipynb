{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0a02e9",
   "metadata": {},
   "source": [
    "# FastText Deep NLP \n",
    "\n",
    "Using FastText library to create the best model for sentiment prediction on imdb dataset.\n",
    "\n",
    "#### Authors\n",
    "* Denjoy Segolene\n",
    "* Le Helloco Quentin\n",
    "* Sharpin Etienne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d7d194",
   "metadata": {},
   "source": [
    "### Import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "476a36a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769332c3",
   "metadata": {},
   "source": [
    "### Create Dataset\n",
    "\n",
    "We use imdb huggingface dataset. It is composed of 25000 samples of positive/negative labeled review for training and 25000 samples for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7948723f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/Users/quentinlehelloco/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28eecd060e3b456d813f0a114a6f93b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f672924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = dataset[\"train\"][:][\"text\"]\n",
    "y_train = dataset[\"train\"][:][\"label\"]\n",
    "\n",
    "x_test = dataset[\"test\"][:][\"text\"]\n",
    "y_test = dataset[\"test\"][:][\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c596a0fe",
   "metadata": {},
   "source": [
    "Let's look at the first sample to see what kind of format is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64dfaa54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83794f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5f619c",
   "metadata": {},
   "source": [
    "Samples are made of a single string composed of multiples sentences. The label indicates 1 for positives reviews and 0 for negatives ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80175af0",
   "metadata": {},
   "source": [
    "### Format dataset for FastText usage\n",
    "\n",
    "FastText use a specific format of input: files where each line is a sample with **\\_\\_label\\_\\_\\<label_name\\>** before each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "95bd1fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "93916928",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Value  Positive\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...         1\n",
       "1  Homelessness (or Houselessness as George Carli...         1\n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...         1\n",
       "3  This is easily the most underrated film inn th...         1\n",
       "4  This is not the typical Mel Brooks film. It wa...         1"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Value':x_train, 'Positive':y_train})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e8c4dc",
   "metadata": {},
   "source": [
    "#### We need to add \"\\__label\\__positive\" and \"\\__label\\__negative\" before every document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "584241a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label(s, p):\n",
    "    if p == 1:\n",
    "        return \"__label__positive \" + s\n",
    "    else:\n",
    "        return \"__label__negative \" + s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cc8f8f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Value\"] = df.apply(lambda x: add_label(x.Value, x.Positive), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9a91b0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__positive Bromwell High is a cartoon c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__positive Homelessness (or Houselessne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__positive Brilliant over-acting by Les...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__positive This is easily the most unde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__positive This is not the typical Mel ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>__label__negative Towards the end of the movie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>__label__negative This is the kind of movie th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>__label__negative I saw 'Descent' last night a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>__label__negative Some films that you pick up ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>__label__negative This is one of the dumbest f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Value  Positive\n",
       "0      __label__positive Bromwell High is a cartoon c...         1\n",
       "1      __label__positive Homelessness (or Houselessne...         1\n",
       "2      __label__positive Brilliant over-acting by Les...         1\n",
       "3      __label__positive This is easily the most unde...         1\n",
       "4      __label__positive This is not the typical Mel ...         1\n",
       "...                                                  ...       ...\n",
       "24995  __label__negative Towards the end of the movie...         0\n",
       "24996  __label__negative This is the kind of movie th...         0\n",
       "24997  __label__negative I saw 'Descent' last night a...         0\n",
       "24998  __label__negative Some films that you pick up ...         0\n",
       "24999  __label__negative This is one of the dumbest f...         0\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3247b0e",
   "metadata": {},
   "source": [
    "The samples are now nicely formatted to be put in a FastText input file. But because we do not want a bias by giving the model all positive samples first, we need to shuffle the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ab593a",
   "metadata": {},
   "source": [
    "### Shuffle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9e18d59f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__positive This is simply a classic fil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__negative Wow. Some movies just leave ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__negative As an ex-teacher(!) I must c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__positive Robert Jannuci,Luca Venantin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__positive I would never have thought I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>__label__positive This project was originally ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>__label__positive When I first watched this, w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>__label__positive Madhur Bhandarkar goes all o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>__label__negative I rented this thinking it mi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>__label__positive When I heard that Adrian Pas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Value  Positive\n",
       "0      __label__positive This is simply a classic fil...         1\n",
       "1      __label__negative Wow. Some movies just leave ...         0\n",
       "2      __label__negative As an ex-teacher(!) I must c...         0\n",
       "3      __label__positive Robert Jannuci,Luca Venantin...         1\n",
       "4      __label__positive I would never have thought I...         1\n",
       "...                                                  ...       ...\n",
       "24995  __label__positive This project was originally ...         1\n",
       "24996  __label__positive When I first watched this, w...         1\n",
       "24997  __label__positive Madhur Bhandarkar goes all o...         1\n",
       "24998  __label__negative I rented this thinking it mi...         0\n",
       "24999  __label__positive When I heard that Adrian Pas...         1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e836264",
   "metadata": {},
   "source": [
    "The samples can now be put in a FasText input file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0258bd9",
   "metadata": {},
   "source": [
    "### Put data as a file for FastText input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e145f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"FastText_input.txt\", 'w+') as f:\n",
    "    for values in df[\"Value\"]:\n",
    "        f.write(values + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc8b9ff",
   "metadata": {},
   "source": [
    "### Create model \n",
    "\n",
    "FastText possess a method to create and train a model automatically so let's use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7a18d37d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 5M words\n",
      "Number of words:  281132\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 2805986 lr:  0.000000 avg.loss:  0.427186 ETA:   0h 0m 0s 67.4% words/sec/thread: 2791510 lr:  0.032629 avg.loss:  0.485156 ETA:   0h 0m 1s\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(\"FastText_input.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969f2872",
   "metadata": {},
   "source": [
    "### Save model\n",
    "\n",
    "The model was fast to compute but we can always save it as a file to keep it after shutting down kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5831f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a94aa18",
   "metadata": {},
   "source": [
    "### Test model predictions\n",
    "\n",
    "Let's test some easy sentences to see if the model predict them correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "16956d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__positive',), array([0.99994802]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"I loved this movie !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f17b2970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__negative',), array([0.98021179]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"I hated this movie !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "47461bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__negative',), array([0.86012012]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"I really enjoyed how bad the actors played\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9f673d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__positive',), array([0.97754908]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"I did not enjoyed it as I should have\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27abbe29",
   "metadata": {},
   "source": [
    "The model seems to correct nicely most of the sentences but the last one is maybe too ambigous and is mispredicted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e836ef",
   "metadata": {},
   "source": [
    "### Test our accuracy\n",
    "\n",
    "A few sentences are great, but using a test dataset is better. Hopefully we got one so let's see the scores for predicting all 25000 test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "abcc4eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_tests(x_test, y_test, model):\n",
    "    \"\"\"\n",
    "    Calculate accuracy of predictions for a model\n",
    "    \n",
    "    Input:\n",
    "        x_test : list of sentences to predict\n",
    "        y_test : list of labels for x_test sentences\n",
    "        model : model to predict from\n",
    "        \n",
    "    Output:\n",
    "        List of predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    preds = []\n",
    "    \n",
    "    number_doc = len(x_test)\n",
    "    \n",
    "    for i in range(number_doc):\n",
    "        pred = model.predict(x_test[i])\n",
    "        \n",
    "        #\n",
    "        if pred[0][0] == '__label__negative':\n",
    "            preds.append(0)\n",
    "        else:\n",
    "            preds.append(1)\n",
    "                \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f687e699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.59 s, sys: 65 ms, total: 1.66 s\n",
      "Wall time: 1.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = pred_tests(x_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "773f01e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2c085517",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86     12500\n",
      "           1       0.86      0.86      0.86     12500\n",
      "\n",
      "    accuracy                           0.86     25000\n",
      "   macro avg       0.86      0.86      0.86     25000\n",
      "weighted avg       0.86      0.86      0.86     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6333be7",
   "metadata": {},
   "source": [
    "0.86 is better than logistic regression or naive bayesian implementation. We expected this because FastText is a great tool to create powerful models. Now, we need to see if we can improve the model to get better scores. \n",
    "\n",
    "First we can try to tune hyperparameters to see if FastText can offer a better model without modifying the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b258c16a",
   "metadata": {},
   "source": [
    "### Hyperparameters fitting\n",
    "\n",
    "To tune hyperparameters, we could do it by hand and try multiples values of learning rates, ngram-word and epoch. But FastText provide an all-in-one method to search for the better hyperparameters combinations for our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291295e7",
   "metadata": {},
   "source": [
    "#### Creating val and train dataset for hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "637debdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_FastText_file(value_column:pd.DataFrame, file_name:str):\n",
    "    \"\"\"\n",
    "    Create a file with FastText Format from a DataFrame\n",
    "    \n",
    "    Input:\n",
    "        value_column : column of dataFrame containing formatted values\n",
    "        file_name : name of the file to create\n",
    "        \n",
    "    Output: None\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(file_name, \"w+\") as f:\n",
    "        for values in value_column:\n",
    "            f.write(values + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da26d25",
   "metadata": {},
   "source": [
    "FastText need a train and validation dataset to tune the hyperparameters according to the validation score. We makes one of 2000 samples, the 23000 remaining samples are used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "014b1ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create val dataset as FastText input file\n",
    "df_to_FastText_file(df[:2000][\"Value\"],\"FastText_val.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "84c03120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train dataset as FastText input file\n",
    "df_to_FastText_file(df[2000:][\"Value\"], \"FastText_train.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca7628c",
   "metadata": {},
   "source": [
    "#### Using FastText hyperparameters tuning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fa747572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% Trials:   12 Best score:  0.881500 ETA:   0h 0m 0s\n",
      "Training again with best arguments\n",
      "Read 5M words\n",
      "Number of words:  266902\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 4008359 lr:  0.000000 avg.loss:  0.060689 ETA:   0h 0m 0s  7.7% words/sec/thread: 3800757 lr:  0.089260 avg.loss:  0.387947 ETA:   0h 0m32s 64.3% words/sec/thread: 3974928 lr:  0.034480 avg.loss:  0.090183 ETA:   0h 0m11s\n"
     ]
    }
   ],
   "source": [
    "tuned_model = fasttext.train_supervised(input='FastText_train.txt', autotuneValidationFile='FastText_val.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2b2d4bcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87     12500\n",
      "           1       0.87      0.87      0.87     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n",
      "CPU times: user 1.37 s, sys: 13.4 ms, total: 1.38 s\n",
      "Wall time: 1.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred_tuned = pred_tests(x_test, y_test, best_model)\n",
    "print(classification_report(y_test, y_pred_tuned))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cb60b3",
   "metadata": {},
   "source": [
    "In 5min of hyperparameters autotune using a validation file, FastText found a best score of 0.88 which is better than our previous 0.86 score.\n",
    "\n",
    "In order to increase this score, we could let autotune execute longer but the best option is to apply treatment to the input data to remove stopword and use lemming/stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9697b0",
   "metadata": {},
   "source": [
    "### Testing pretreatment methods\n",
    "\n",
    "Pretreating the data may be the most complicated part because of the large volume of samples in the dataset. Applying stopword removal, stemming and/or flemming can be very long to execute.\n",
    "\n",
    "First, let's create an all-in-one function to create and train a model so we just need to put pretreated samples as input to calculate the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "60be940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_predict(x_train:list, y_train:list ,x_test:list, y_test:list, file_name:str):\n",
    "    \"\"\"\n",
    "    Predict samples from x_test using FastText trained model with x_train samples.\n",
    "    \n",
    "    Input:\n",
    "        x_train: list of samples (train)\n",
    "        y_train: list of labels (train)\n",
    "        x_test: list of samples (test)\n",
    "        y_test: list of labels (test)\n",
    "        file_name: name of file created for FastText input formatting\n",
    "    \"\"\"\n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame({'Value':x_train, 'Positive':y_train})\n",
    "    \n",
    "    # Format samples\n",
    "    df[\"Value\"] = df.apply(lambda x: add_label(x.Value, x.Positive), axis=1)\n",
    "    \n",
    "    # Shuffle data\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # Create file\n",
    "    with open(file_name, 'w+') as f:\n",
    "        for values in df[\"Value\"]:\n",
    "            f.write(values + \"\\n\")\n",
    "            \n",
    "    # Train model\n",
    "    print(\"Training model\")\n",
    "    model = fasttext.train_supervised(file_name)\n",
    "    \n",
    "    # Predict test\n",
    "    print(\"Predicting test samples\")\n",
    "    y_pred = pred_tests(x_test, y_test, model)\n",
    "    \n",
    "    # Print scores\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return (model, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384efdf5",
   "metadata": {},
   "source": [
    "#### Now we just need to add pretreatment and test a new training\n",
    "\n",
    "We can start by removing stopword to see if it affects the prediction scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f43114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Reg expr for tokenization\n",
    "re_word = re.compile(r\"^\\w+$\")\n",
    "\n",
    "# loading small English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f369bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword_removal(text:str):\n",
    "    tokens_str = [str(token) for token in nlp(text.lower()) if re_word.match(token.text) and not token.is_stop]\n",
    "    return \" \".join(tokens_str)\n",
    "\n",
    "def process_treatment(func, data):\n",
    "    with Pool() as p:\n",
    "        preproc_data = p.map(func, data)\n",
    "        \n",
    "    return preproc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c012e691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-22:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/queues.py\", line 368, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'stopword_removal' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-23:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/queues.py\", line 368, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'stopword_removal' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/queues.py\", line 368, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'stopword_removal' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-21:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/queues.py\", line 368, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'stopword_removal' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-26:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/queues.py\", line 368, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'stopword_removal' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-25:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/queues.py\", line 368, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'stopword_removal' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-28:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/queues.py\", line 368, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'stopword_removal' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-27:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/queues.py\", line 368, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'stopword_removal' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-29:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/queues.py\", line 368, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'stopword_removal' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-30:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/queues.py\", line 368, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'stopword_removal' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-31:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/queues.py\", line 368, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'stopword_removal' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-32:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/queues.py\", line 368, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'stopword_removal' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-33:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/queues.py\", line 368, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'stopword_removal' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-34:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/queues.py\", line 368, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'stopword_removal' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-35:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/queues.py\", line 368, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'stopword_removal' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-36:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/queues.py\", line 368, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'stopword_removal' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-39:\n",
      "Process SpawnPoolWorker-37:\n",
      "Process SpawnPoolWorker-40:\n",
      "Process SpawnPoolWorker-38:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/queues.py\", line 366, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/connection.py\", line 221, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/quentinlehelloco/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ks/_8c7lp5x3vl43h8nt9t42y2m0000gn/T/ipykernel_21851/575791331.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreproc_x_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_treatment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopword_removal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/ks/_8c7lp5x3vl43h8nt9t42y2m0000gn/T/ipykernel_21851/30370070.py\u001b[0m in \u001b[0;36mprocess_treatment\u001b[0;34m(func, data)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_treatment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mpreproc_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpreproc_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "preproc_x_train = process_treatment(stopword_removal, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa355788",
   "metadata": {},
   "source": [
    "### Find wrongly classified samples to analyze why it failed\n",
    "\n",
    "To understand why some samples were predicted incorrectly, we can take a look at some of it to see if we can detect a pattern that may be difficult for the model to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1b44effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_wrong_class(x_pred:list, y_pred:list, y_true:list, nb_samples=None) -> list:\n",
    "    \"\"\"\n",
    "    Find wrong classification of samples in x_pred based on y_pred prediction\n",
    "    \n",
    "    Input:\n",
    "        x_pred: list of samples\n",
    "        y_pred: list of predicted labels\n",
    "        y_true: list of true labels\n",
    "        nb_samples: max number of samples to extract (could be less if not enough in provided samples)\n",
    "    \"\"\"\n",
    "    wrongly_classified = []\n",
    "    count_sample = 0\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        if nb_samples is not None and count_sample == nb_samples:\n",
    "            break\n",
    "        \n",
    "        if y_pred[i] != y_true[i]:\n",
    "            wrongly_classified.append((x_pred[i], y_pred[i]))\n",
    "            count_sample += 1\n",
    "            \n",
    "    return wrongly_classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4ac6fdcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Four things intrigued me as to this film - firstly, it stars Carly Pope (of \"Popular\" fame), who is always a pleasure to watch. Secdonly, it features brilliant New Zealand actress Rena Owen. Thirdly, it is filmed in association with the New Zealand Film Commission. Fourthly, a friend recommended it to me. However, I was utterly disappointed. The whole storyline is absurd and complicated, with very little resolution. Pope\\'s acting is fine, but Owen is unfortunately under-used. The other actors and actresses are all okay, but I am unfamiliar with them all. Aside from the nice riddles which are littered throughout the movie (and Pope and Owen), this film isn\\'t very good. So the moral of the story is...don\\'t watch it unless you really want to.',\n",
       " 1)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_wrong = find_wrong_class(x_test, y_pred, y_test)\n",
    "few_wrong[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7d9dc9d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"The plot of this movie is as dumb as a bag of hair. Jimmy Smit plays a character that could have been upset by the ridiculousness of the story. He is evil and a wife beater. It's a character as far from his NYPD and LA Law roles as you could possibly get.<br /><br />If you've thought he had the looks and the acting chops to play the really bad boy role, her's your present.<br /><br />But!!!!!!!! Mary Louis Parker wears black miniskirts and little black minidresses throughout the movie.<br /><br />She has always had some of the greatest legs in the history of the movies. This makes the movie well worth it for this leg admirer.<br /><br />I'd buy the DVD for this reason only if it was available.\",\n",
       " 0)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_wrong[42]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c007c208",
   "metadata": {},
   "source": [
    "If we take those two samples that were mispredicted, we can see that they do not clearly state if they like or not the movie but implies it with complicated word and phrasing of sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7981760",
   "metadata": {},
   "source": [
    "### Improve model\n",
    "\n",
    "Now that we have seen all that we could do with FastText, let's try to beat the baseline and target a prediction score of 0.90.\n",
    "\n",
    "To do so, we are going to use pretrained embedding by FastText and merge the into a classifier to finetune them for our particular sentiment prediction project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686faf95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Console Py",
   "language": "python",
   "name": "console_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
